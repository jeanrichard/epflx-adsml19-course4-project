{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4 - Project - Part 1: Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top-1\"></a>\n",
    "This notebook is concerned with *Part 1: Feature extraction*.\n",
    "\n",
    "**Contents:**\n",
    "* [Step 1: Take a first look at the data set](#step-1.1)\n",
    "* [Step 2: Set up a pretrained model](#step-1.2)\n",
    "* [Step 3: Extract features](#step-1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Take a first look at the data set<a name=\"step-1.1\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library.\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the Swissroads data set has been downloaded and extracted into a directory named _data/_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path.cwd() / 'data' / 'swissroads'\n",
    "assert base_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data set is rather small (469 images) and has already been divided into 3 sub subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 280 images\n",
      "valid: 139 images\n",
      "test: 50 images\n"
     ]
    }
   ],
   "source": [
    "for kind in ['train', 'valid', 'test']:\n",
    "    path = base_path / kind\n",
    "    num = sum(1 for _ in path.glob('**/*.png'))\n",
    "    print(f'{kind}: {num} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up a pretrained model<a name=\"step-1.2\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the MobileNet v2 CNN model from TensorFlow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet V2.\n",
    "# (An updated implementation exists but it requires TF 1.5 or TF 2.)\n",
    "MOBILENET_V2_VERSION = 3  # implementation version\n",
    "MOBILENET_V2_URL = f'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/{MOBILENET_V2_VERSION}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download and setup the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/nv/rl462mms4sg561l5l80lhh_hqg2chr/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Create graph.\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module.\n",
    "    module_url = MOBILENET_V2_URL\n",
    "    module = hub.Module(module_url)\n",
    "    \n",
    "    # Get the expected size.\n",
    "    height, width = hub.get_expected_image_size(module)\n",
    "    \n",
    "    # Create an input placeholder.\n",
    "    # n [samples] x height [pixels] x width [pixels] x 3 [color channels]\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, height, width, 3])\n",
    "    \n",
    "    # Get a node with the features.\n",
    "    imgs_features = module(input_imgs)\n",
    "    \n",
    "    # Collect initializers.\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "    \n",
    "img_graph.finalize()  # Make the graph \"read-only\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract features<a name=\"step-1.3\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library.\n",
    "import os\n",
    "import pathlib\n",
    "import typing as T\n",
    "\n",
    "# 3rd party.\n",
    "import numpy as np\n",
    "import PIL as pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the documentation of MobileNet v2, we need to resize images and scale color channels:\n",
    "\n",
    "> The input images are expected to have color values in the range [0,1], following the common image input conventions. For this module, the size of the input images is fixed to height x width = 224 x 224 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load and normalize images while keeping track of their labels. It may be possible to \"hijack\" an `ImageDataGenerator` by disabling all data augmentations and reading the exact number of images. Here, we decide to do it by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(path: os.PathLike,\n",
    "                   rescale: T.Optional[float] = 1/255,\n",
    "                   target_size: T.Tuple[int, int] = (224, 224),\n",
    "                   resample: int = pil.Image.BICUBIC ) -> np.ndarray:\n",
    "    \"\"\"\\\n",
    "    Loads an image from file.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the root of the directory structure.\n",
    "        rescale: An optional rescaling factor. If ``None`` or zero, no rescaling is applied. \n",
    "            Otherwise, all values are multipled by the rescaling factor.\n",
    "        target_size: A tuple of integers ``(height, width)`` that specifies the dimensions to which\n",
    "            the image will be resized.\n",
    "        resample: The ID of an optional resampling filter for resizing. See\n",
    "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize\n",
    "\n",
    "    Returns:\n",
    "        The image, returned as a NumPy array of shape\n",
    "        ``1 [samples] x height [pixels] x width [pixels] x 3 [color channels]``.\n",
    "    \"\"\"\n",
    "    img = pil.Image.open(path)\n",
    "    img = img.resize(target_size, resample)\n",
    "    array = np.asarray(img, dtype=np.float32)  # height x width x 3\n",
    "    array = array[np.newaxis, :, : :]  # 1 x height x width x 3\n",
    "    if rescale:  # Do not rescale if None or 0.\n",
    "        array *= rescale\n",
    "    return array\n",
    "\n",
    "\n",
    "def load_images(path: os.PathLike,\n",
    "                rescale: T.Optional[float] = 1/255,\n",
    "                target_size: T.Tuple[int, int] = (224, 224),\n",
    "                resample: int = pil.Image.BICUBIC) -> T.Iterator[T.Tuple[np.ndarray, str]]:\n",
    "    \"\"\"\\\n",
    "    Loads images from a directory structure. The names of the sub-directories are interpreted as\n",
    "    labels for the images that they contain. The expected directory structure is::\n",
    "\n",
    "        <path>/<label>/*.png\n",
    "  \n",
    "    Args:\n",
    "        path: The path to the root of the directory structure.\n",
    "        rescale: An optional rescaling factor. If ``None`` or zero, no rescaling is applied. \n",
    "            Otherwise, all values are multipled by the rescaling factor.\n",
    "        target_size: A tuple of integers ``(height, width)`` that specifies the dimensions to which\n",
    "            the image will be resized.\n",
    "        resample: The ID of an optional resampling filter for resizing. See\n",
    "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize\n",
    "\n",
    "    Returns:\n",
    "        An iterator over pairs ``(image, label)``. Each image is returned as a NumPy array of shape\n",
    "        ``1 [samples] x height [pixels] x width [pixels] x 3 [color channels]``.\n",
    "    \"\"\"\n",
    "    label_paths = [entry for entry in path.iterdir() if entry.is_dir()]\n",
    "    for label_path in sorted(label_paths):\n",
    "        label = label_path.name\n",
    "        image_paths = label_path.glob('*.png')\n",
    "        for image_path in image_paths:\n",
    "            array = image_to_array(image_path, rescale, target_size, resample)\n",
    "            yield (array, label)\n",
    "\n",
    "\n",
    "def load_dataset(path: os.PathLike,\n",
    "                 rescale: T.Optional[float] = 1/255,\n",
    "                 target_size: T.Tuple[int, int] = (224, 224),\n",
    "                 resample: int = pil.Image.BICUBIC) -> T.Dict[str, T.Any]:\n",
    "    \"\"\"\\\n",
    "    Loads a dataset from a directory structure. The names of the sub-directories are interpreted as\n",
    "    labels for the images that they contain. The expected directory structure is::\n",
    "\n",
    "        <path>/<label>/<name>.png\n",
    "\n",
    "    Args:\n",
    "        path: The path to the root of the directory structure.\n",
    "        rescale: An optional rescaling factor. If ``None`` or zero, no rescaling is applied. \n",
    "            Otherwise, all values are multipled by the rescaling factor.\n",
    "        target_size: A tuple of integers ``(height, width)`` that specifies the dimensions to which\n",
    "            the image will be resized.\n",
    "        resample: The ID of an optional resampling filter for resizing. See\n",
    "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize\n",
    "\n",
    "    Returns:\n",
    "        A dataset as a dictionary with the following entries:\n",
    "        \n",
    "        - ``data``: The list of images, as a NumPy array of shape\n",
    "          ``n [samples] x height [pixels] x width [pixels] x 3 [color channels]``. \n",
    "        - ``labels``: The list of numeric labels of the images, as a Numpy array of shape\n",
    "          ``n [samples]``. Text labels can be reconstructed using ``names[labels]``.\n",
    "        - ``names``: The list of unique text labels of the images, as a NumPy array of shape\n",
    "          ``k [categories]``.\n",
    "    \"\"\"\n",
    "    buf_images = []\n",
    "    buf_labels = []\n",
    "    for image, label in load_images(path, rescale, target_size, resample):\n",
    "        buf_images.append(image)\n",
    "        buf_labels.append(label)\n",
    "    # Collect all images into a single array.\n",
    "    images = np.concatenate(buf_images)\n",
    "    # Collect all labels into a single array. \n",
    "    labels = np.array(buf_labels)\n",
    "    # Figure out numeric indices for the labels.\n",
    "    label_names, label_idxs = np.unique(labels, return_inverse=True)\n",
    "    # We mimic the naming used in CIFAR-10.\n",
    "    dataset = {\n",
    "        'data': images,\n",
    "        'labels': label_idxs,\n",
    "        'names': label_names\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the training, validation and test datasets. Since the dataset is rather small, we decide to use bicubic interpolation when resizing the images and to save both images and extracted features in the same NPZ file (this is most likely less efficient than PNG compression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Dataset: train\n",
      "Loading dataset (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads/train)...\n",
      "Extracting features...\n",
      "Features: shape=(280, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads-features-train.npz)...\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: valid\n",
      "Loading dataset (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads/valid)...\n",
      "Extracting features...\n",
      "Features: shape=(139, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads-features-valid.npz)...\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: test\n",
      "Loading dataset (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads/test)...\n",
      "Extracting features...\n",
      "Features: shape=(50, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/ContEd/Adsml/git/course-04-project/data/swissroads-features-test.npz)...\n"
     ]
    }
   ],
   "source": [
    "separator = ''.center(80, '-')\n",
    "\n",
    "# Create a session.\n",
    "with tf.Session(graph=img_graph) as sess:\n",
    "    # Initialize the session.\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Extract the features.\n",
    "    for kind in ['train', 'valid', 'test']:\n",
    "        print(separator)\n",
    "        print(f'Dataset: {kind}')\n",
    "        \n",
    "        # Load the dataset.\n",
    "        path = base_path / kind\n",
    "        print(f'Loading dataset ({path})...')\n",
    "        dataset = load_dataset(path)\n",
    "        \n",
    "        # Extract the features and add them to the dataset.\n",
    "        print('Extracting features...')\n",
    "        features = sess.run(imgs_features, feed_dict={input_imgs: dataset['data']})\n",
    "        print(f'Features: shape={features.shape}, dtype={features.dtype}')\n",
    "        dataset['features'] = features\n",
    "        \n",
    "        # Save the dataset.\n",
    "        ouput_path = pathlib.Path.cwd() / 'data' / f'swissroads-features-{kind}.npz'\n",
    "        print(f'Saving ({ouput_path})...')\n",
    "        np.savez(ouput_path, **dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
