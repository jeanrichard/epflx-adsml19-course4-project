{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4 - Project - Part 1: Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top-1\"></a>\n",
    "This notebook is concerned with *Part 1: Feature extraction*.\n",
    "\n",
    "**Contents:**\n",
    "* [Step 1: Take a first look at the dataset](#step-1.1)\n",
    "* [Step 2: Set up a pretrained model](#step-1.2)\n",
    "* [Step 3: Extract features](#step-1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Take a first look at the dataset<a name=\"step-1.1\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library.\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We assume that the Swissroads dataset has been downloaded and extracted into a directory named _data/_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path.cwd() / 'data' / 'swissroads'\n",
    "assert base_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset is rather small (469 images) and has already been divided into 3 subsets for training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 280 images\n",
      "valid: 139 images\n",
      "test: 50 images\n"
     ]
    }
   ],
   "source": [
    "for kind in ['train', 'valid', 'test']:\n",
    "    path = base_path / kind\n",
    "    num = sum(1 for _ in path.glob('**/*.png'))\n",
    "    print(f'{kind}: {num} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up a pretrained model<a name=\"step-1.2\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "# 3rd party.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the MobileNet v2 CNN model from TensorFlow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet V2.\n",
    "# (An updated implementation version exists but seems to require TF 1.15 or TF 2.)\n",
    "MOBILENET_V2_VERSION = 3  # implementation version\n",
    "MOBILENET_V2_URL = f'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/{MOBILENET_V2_VERSION}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download and setup the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Create graph.\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module.\n",
    "    module_url = MOBILENET_V2_URL\n",
    "    module = hub.Module(module_url)\n",
    "    \n",
    "    # Get the expected size.\n",
    "    height, width = hub.get_expected_image_size(module)\n",
    "    \n",
    "    # Create an input placeholder.\n",
    "    # ? [samples] x height [pixels] x width [pixels] x 3 [color channels]\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, height, width, 3])\n",
    "    \n",
    "    # Get a node with the features.\n",
    "    imgs_features = module(input_imgs)\n",
    "    \n",
    "    # Collect the initializers.\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "    \n",
    "img_graph.finalize()  # Make the graph \"read-only\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract features<a name=\"step-1.3\"></a> ([top](#top-1))\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library.\n",
    "import os\n",
    "import pathlib\n",
    "import typing as T\n",
    "\n",
    "# 3rd party.\n",
    "import numpy as np\n",
    "\n",
    "# Project.\n",
    "import datasetutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the documentation of MobileNet v2, we need to resize images and scale color channels:\n",
    "\n",
    "> The input images are expected to have color values in the range [0,1], following the common image input conventions. For this module, the size of the input images is fixed to height x width = 224 x 224 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** We need to load and process images while keeping track of their labels. It may be possible to \"hijack\" an `ImageDataGenerator` by disabling all data augmentations and reading the exact number of images. Here, we decide to do it by hand. The corresponding code is in **datasetutils.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the training, validation and test datasets. Since the datasets are rather small, we decide to use bicubic interpolation when resizing the images and to save both images and extracted features in the same NPZ file (this is most likely less efficient than PNG compression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Dataset: train\n",
      "Loading dataset (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads/train)...\n",
      "Extracting features...\n",
      "Features: shape=(280, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads-features-train.npz)...\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: valid\n",
      "Loading dataset (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads/valid)...\n",
      "Extracting features...\n",
      "Features: shape=(139, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads-features-valid.npz)...\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: test\n",
      "Loading dataset (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads/test)...\n",
      "Extracting features...\n",
      "Features: shape=(50, 1280), dtype=float32\n",
      "Saving (/Users/taariet1/cont-edu/Adsml/git/course-04-project/data/swissroads-features-test.npz)...\n"
     ]
    }
   ],
   "source": [
    "separator = ''.center(80, '-')\n",
    "\n",
    "# Create a session.\n",
    "with tf.Session(graph=img_graph) as sess:\n",
    "    # Initialize the session.\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Extract the features.\n",
    "    for kind in ['train', 'valid', 'test']:\n",
    "        print(separator)\n",
    "        print(f'Dataset: {kind}')\n",
    "        \n",
    "        # Load the dataset.\n",
    "        path = base_path / kind\n",
    "        print(f'Loading dataset ({path})...')\n",
    "        dataset = datasetutils.load_dataset(path)\n",
    "        \n",
    "        # Extract the features and add them to the dataset.\n",
    "        print('Extracting features...')\n",
    "        features = sess.run(imgs_features, feed_dict={input_imgs: dataset['data']})\n",
    "        print(f'Features: shape={features.shape}, dtype={features.dtype}')\n",
    "        dataset['features'] = features\n",
    "        \n",
    "        # Save the dataset.\n",
    "        ouput_path = pathlib.Path.cwd() / 'data' / f'swissroads-features-{kind}.npz'\n",
    "        print(f'Saving ({ouput_path})...')\n",
    "        np.savez(ouput_path, **dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
